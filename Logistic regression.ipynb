{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x1         x2  result\n",
      "0   34.623660  78.024693       0\n",
      "1   30.286711  43.894998       0\n",
      "2   35.847409  72.902198       0\n",
      "3   60.182599  86.308552       1\n",
      "4   79.032736  75.344376       1\n",
      "..        ...        ...     ...\n",
      "95  83.489163  48.380286       1\n",
      "96  42.261701  87.103851       1\n",
      "97  99.315009  68.775409       1\n",
      "98  55.340018  64.931938       1\n",
      "99  74.775893  89.529813       1\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "col_names=['x1','x2','result']\n",
    "data=pd.read_csv('F://Student-University.csv',header=None,names=col_names)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are\n",
      "\tx1\t\t\t x2\n",
      "0.06542783839708051 \t 0.6946548758545597\n",
      "0.0032663246504238525 \t 0.19470454840650325\n",
      "0.08296784226643318 \t 0.6196177879139748\n",
      "0.43176427463677125 \t 0.816001349157813\n",
      "0.701943395867806 \t 0.6553921446737926\n",
      "0.21534560359949134 \t 0.37665959002217975\n",
      "0.44500890594583803 \t 0.9654585899091591\n",
      "0.6444968444013321 \t 0.23365526033649311\n",
      "0.6598910823266816 \t 0.8322907876763868\n",
      "0.7793428307734228 \t 0.18940757339377604\n",
      "0.943150959303037 \t 0.11165141606384167\n",
      "0.6443379317842325 \t 0.0\n",
      "0.7488742055539973 \t 0.6720561353176704\n",
      "0.5633697830680986 \t 0.9831432796407118\n",
      "0.13586996928430367 \t 0.6655353002740068\n",
      "0.3427341309800695 \t 0.8584645184467513\n",
      "0.559149505425977 \t 0.3242778331648405\n",
      "0.5430494035059064 \t 0.235479891268918\n",
      "0.5819585564902039 \t 0.9129539912446455\n",
      "0.6725040850088234 \t 0.24862534101371722\n",
      "0.5348103913550812 \t 0.1792274949676976\n",
      "0.854504480403426 \t 0.5155716426733061\n",
      "0.2934821405696847 \t 0.2673732484024392\n",
      "0.05952839263385338 \t 0.19931197062508343\n",
      "0.6860531862004597 \t 0.5620513842984165\n",
      "0.4616975289740767 \t 0.5764376890213909\n",
      "0.7185330576596541 \t 0.20827834895705072\n",
      "0.9037758087621315 \t 0.12008007492728852\n",
      "0.45537943029622235 \t 0.2878855505942002\n",
      "0.12508387576552607 \t 0.5037988284016072\n",
      "0.44891644040768586 \t 0.6182362732262108\n",
      "0.7932702045019747 \t 0.38743523735896646\n",
      "0.3160307028668126 \t 0.4764345113274903\n",
      "0.315133815591733 \t 0.5687970405007258\n",
      "0.14588235653454537 \t 0.5942106214327147\n",
      "0.3522520123248343 \t 0.31656414671313754\n",
      "0.05527778391449414 \t 1.0\n",
      "0.4890158828890846 \t 0.7368920141616419\n",
      "0.6411215274169618 \t 0.16069674916069207\n",
      "0.05912103498790884 \t 0.6538297881496388\n",
      "0.7717402274503428 \t 0.37653763269406415\n",
      "0.30800050068343104 \t 0.23808317402911625\n",
      "0.9228240722694757 \t 0.5121959690193272\n",
      "0.7497585576120482 \t 0.14670504529213127\n",
      "0.3008344491894999 \t 0.22294260349473338\n",
      "0.4610047014216028 \t 0.3143244733232518\n",
      "0.6755749487369113 \t 0.5838167763713695\n",
      "0.9705276343626557 \t 0.8221430473750168\n",
      "0.4588603123061525 \t 0.9692290992337048\n",
      "0.8815680443545076 \t 0.8509782690905985\n",
      "0.7150162710397858 \t 0.6380884487645637\n",
      "0.9920404393264983 \t 0.4452537274672527\n",
      "0.8669733121084352 \t 0.1873158858895574\n",
      "0.0640067814840441 \t 0.43642521815084545\n",
      "0.2899233674154562 \t 0.28127072126663155\n",
      "0.2798928589457701 \t 0.4278207886302955\n",
      "0.9687221726794305 \t 0.560428512150666\n",
      "0.03609592288851958 \t 0.9520862528286486\n",
      "0.6333736549218321 \t 0.5745350377488155\n",
      "0.5982258375885657 \t 0.7009371883708675\n",
      "0.6498124675590775 \t 0.8079649321473289\n",
      "0.07492278406569655 \t 0.24048881190160637\n",
      "0.3754530203634241 \t 0.12683015557568714\n",
      "0.0 \t 0.2781716030325017\n",
      "0.20939718023491344 \t 0.5251037461452664\n",
      "0.523184416079217 \t 0.1536461539346378\n",
      "0.1490450380721797 \t 0.9804551771259103\n",
      "0.27252405991592943 \t 0.3117202533492382\n",
      "0.7198143317886652 \t 0.9010728933277937\n",
      "0.5258478340133736 \t 0.4451418569797301\n",
      "0.0381832796832556 \t 0.18609377621308795\n",
      "0.4870426801737341 \t 0.6947573453462977\n",
      "0.6061094519633488 \t 0.9613008511702775\n",
      "0.4357099555340205 \t 0.6224420281329758\n",
      "0.41253449507525697 \t 0.6629225488417528\n",
      "1.0 \t 0.6118109037661646\n",
      "0.24660576964677786 \t 0.8477493265280474\n",
      "0.2923838239652542 \t 0.6622107939825964\n",
      "0.43567656751327 \t 0.1743930525511163\n",
      "0.7477219495482103 \t 0.17749076686883383\n",
      "0.8435701264142532 \t 0.5742306068830461\n",
      "0.928430269173845 \t 0.2210618087280253\n",
      "0.5340540374835496 \t 0.5271438052972512\n",
      "0.38956943769755015 \t 0.42350431680881123\n",
      "0.7210639117715709 \t 0.8841404527426612\n",
      "0.5505264498400435 \t 0.8055387001804534\n",
      "0.17223445945207558 \t 0.7066680465047798\n",
      "0.6509890717587513 \t 0.876294562453125\n",
      "0.6962487249008524 \t 0.967450810726579\n",
      "0.31947097201767466 \t 0.44189150967239427\n",
      "0.9178213280255708 \t 0.6819752763080462\n",
      "0.8655663392370524 \t 0.8335831120700983\n",
      "0.36439286515088676 \t 0.07276576461456573\n",
      "0.6368709234274944 \t 0.7945644471579882\n",
      "0.856927202161754 \t 0.21613955840044505\n",
      "0.7658173862081353 \t 0.2604074890443861\n",
      "0.1749039283513614 \t 0.8276513188391145\n",
      "0.9926493323660378 \t 0.5591663460318994\n",
      "0.36235552037054214 \t 0.5028650870234647\n",
      "0.6409300390305599 \t 0.8631881282251196\n"
     ]
    }
   ],
   "source": [
    "x1 = data['x1'].tolist()\n",
    "x2 = data['x2'].tolist()\n",
    "y = data['result'].tolist()\n",
    "\n",
    "\n",
    "#Min max of each column\n",
    "x1_min = min(x1)\n",
    "x2_min = min(x2)\n",
    "x1_max = max(x1)\n",
    "x2_max = max(x2)\n",
    "\n",
    "#Min-max normalization\n",
    "\n",
    "for i in range(len(x1)):\n",
    "    x1[i] = (x1[i] - x1_min) / (x1_max - x1_min)\n",
    "    x2[i] = (x2[i] - x2_min) / (x2_max - x2_min)\n",
    "    \n",
    "print(\"Columns are\")\n",
    "print(\"\\tx1\\t\\t\\t x2\")\n",
    "for i in range(len(x1)):\n",
    "    print(x1[i],\"\\t\",x2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to input and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = data.iloc[:, [0, 1]].values\n",
    "  \n",
    "# output\n",
    "y = data.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp=preprocessing.scale(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 0.9875270298732238\n",
      "b1 2.669884877890649\n",
      "b2 2.7274062957733918\n",
      "y_test [1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1]\n",
      "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n",
      "Accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(xp):\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(xp, y, test_size = 0.20, random_state = 0)\n",
    "    x1=xtrain[:,0]\n",
    "    x2=xtrain[:,1]\n",
    "    # print(\"x1\",x1)\n",
    "    # print(\"x2\",x2)\n",
    "    b0=0.0\n",
    "    b1=0.0\n",
    "    b2=0.0\n",
    "    epoch=10000\n",
    "    alpha=0.001\n",
    "    while(epoch>0):\n",
    "        for i in range(len(xtrain)):\n",
    "            prediction=1/(1+np.exp(-(b0+b1*x1[i]+b2*x2[i])))\n",
    "            b0=b0+alpha*(ytrain[i]-prediction)*prediction*(1-prediction)*1.0\n",
    "            b1=b1+alpha*(ytrain[i]-prediction)*prediction*(1-prediction)*x1[i]\n",
    "            b2=b2+alpha*(ytrain[i]-prediction)*prediction*(1-prediction)*x2[i]\n",
    "        epoch=epoch-1\n",
    "print(\"b0\",b0)\n",
    "print(\"b1\",b1)\n",
    "print(\"b2\",b2)\n",
    "final_prediction=[]\n",
    "x3=xtest[:,0]\n",
    "x4=xtest[:,1]\n",
    "print(\"y_test\",ytest)\n",
    "y_pred=[0]*len(xtest)\n",
    "\n",
    "for i in range(len(xtest)):\n",
    "    y_pred[i]=np.round(1/(1+np.exp(-(b0+b1*x3[i]+b2*x4[i]))))\n",
    "    final_prediction.append(np.ceil(y_pred[i]))\n",
    "print(final_prediction)    \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy\",accuracy_score(ytest,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
